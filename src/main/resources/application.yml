# Server Configuration
server:
  port: 8080

azure:
  openai:
    endpoint: <endpoint>
    key: <key>
    api-version: 2025-01-01-preview

# Spring Configuration
spring:
  # Thymeleaf Configuration
  thymeleaf:
    cache: false
    prefix: classpath:/templates/
    suffix: .html
  
  # AI Configuration
  ai:
    azure:
      openai:
        endpoint: <endpoint>
        api-key: <key>
        chat:
          options:
            deployment-name: gpt-5
            temperature: 1
#    Ollama Configuration
#    ollama:
#      base-url: http://192.168.50.132:11434
#      chat:
#        options:
#          model: gpt-oss:20b
#          temperature: 0.8
    mcp:
      client:
        sse:
          connections:
            author-tools-server:
              url: http://127.0.0.1:9090


    
    # OpenAI Configuration (optional)
    # openai:
    #   api-key: your-api-key-here
    #   chat:
    #     options:
    #       model: gpt-4

# MCP Server Configuration
# Update this URL with your actual MCP server address and port
# Examples:
#   http://localhost:3000/sse
#   http://127.0.0.1:8000/sse
#   http://your-mcp-server:port/sse
mcp:
  server:
    url: http://127.0.0.1:9090
    endpoint: /sse
    timeout: 30000

# Logging
logging:
  level:
    com.example.mcpclient: DEBUG
    org.springframework.web: INFO
    org.springframework.ai: DEBUG